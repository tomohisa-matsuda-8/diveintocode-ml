{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sprint_13.ipynb","provenance":[{"file_id":"1TDmGUKT8MXyKbvDAXiNzg2JwoykRjKK3","timestamp":1615958790085}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rUWNHGMqjnma"},"source":["### 【問題1】スクラッチを振り返る\n","\n","ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n","\n","・重み、バイアスの初期化\n","\n","・エポックのループ\n","\n","・層ごとのノード数の設定\n","\n","・層ごとの活性化関数の決定\n","\n","・線形結合の数式のコーディング\n","\n","・\u0010順伝播、逆伝播の数式のコーディング\n","\n","・損失関数の計算\n","\n","・重み、バイアスの更新"]},{"cell_type":"markdown","metadata":{"id":"hCBlGHpAja8G"},"source":["### 問題2】スクラッチとTensorFlowの対応を考える\n","\n","以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n","\n","\n","\n","・重み、バイアスの初期化\n","\n","　→init = tf.global_variables_initializer()\n","\n","・エポックのループ\n","　→for epoch in range(num_epochs):\n","\n","・層ごとにノード数の設定\n","\n","　→ノード数などパラメータを設定している\n","\n","・線形結合のコーディング\n","\n","　→記載変更が変更となったが、処理内容は同様\n","\n","・損失関数の計算\n","　→loss_op = tf.reduce_mean(tf.nn.\n","\n","・重み、バイアスの更新\n","　→optimizer = tf.train.AdamOptimizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":990},"id":"pD6GGSoU2C-B","executionInfo":{"status":"ok","timestamp":1616261823375,"user_tz":-540,"elapsed":64088,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"9eba0e7d-70b4-4c9a-b110-a843d8c699f7"},"source":["!pip install --upgrade tensorflow==1.15.0"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 32kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.8)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 34.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 27.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (54.1.2)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=c2bedf42d80cafe1dc28b601ae15e6e62d4adb7ba77d8323c94088f6421d137e\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, tensorflow-estimator, tensorboard, tensorflow\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 1.14.0\n","    Uninstalling tensorflow-estimator-1.14.0:\n","      Successfully uninstalled tensorflow-estimator-1.14.0\n","  Found existing installation: tensorboard 1.14.0\n","    Uninstalling tensorboard-1.14.0:\n","      Successfully uninstalled tensorboard-1.14.0\n","  Found existing installation: tensorflow 1.14.0\n","    Uninstalling tensorflow-1.14.0:\n","      Successfully uninstalled tensorflow-1.14.0\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow","tensorflow_estimator"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"9ps_MyPdoFzF"},"source":["### 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHttstv02Ogg","executionInfo":{"status":"ok","timestamp":1616261241437,"user_tz":-540,"elapsed":3614,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"71ec1928-2cf6-4bc9-a4c5-cc9261223dde"},"source":["\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# データセットの読み込み\n","df = pd.read_csv('drive/My Drive/Sprint13/Iris.csv', dtype = None)\n","# データフレームから条件抽出\n","#３種とするので下記処理は削除\n","#df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","# NumPy 配列に変換\n","X = np.array(X)\n","y = np.array(y)\n","\n","# ラベルをone-hot化）\n","y[y == \"Iris-versicolor\"] = 0\n","y[y == \"Iris-virginica\"] = 1\n","y[y == \"Iris-setosa\"] = 2\n","y = y.astype(np.int64)[:, np.newaxis]\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","y = enc.fit_transform(y)\n","\n","#y[y == \"Iris-versicolor\"] = 0\n","#y[y == \"Iris-virginica\"] = 1\n","#y[y == \"Iris-setosa\"] = 2\n","#y = y.astype(np.int64)[:, np.newaxis]\n","\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.001\n","batch_size = 10\n","num_epochs = 100\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1] # → 4\n","n_samples = X_train.shape[0]\n","\n","n_classes = 3  #one-hotの３値分類なので変更\n","\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    tf.random.set_random_seed(0)\n","    # 重みとバイアスの宣言\n","    weights = {\n","        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n","        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n","    }\n","    biases = {\n","        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n","        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n","        'b3': tf.Variable(tf.random_normal([n_classes]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n","    return layer_output\n","# ネットワーク構造の読み込み                               \n","logits = example_net(X)  \n","# 目的関数(2種→3種に改変必要)\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n","# 最適化手法\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# 推定結果(2種→3種に改変必要)\n","#correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","correct_pred = tf.equal(tf.argmax(Y, axis=1), tf.argmax(logits, axis=1))\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","# variableの初期化\n","init = tf.global_variables_initializer()\n","\n","# 計算グラフの実行\n","with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n","        total_loss = 0\n","        total_acc = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","        total_loss /= n_samples\n","        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","WARNING:tensorflow:From <ipython-input-5-3b2f83b9915a>:119: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Epoch 0, loss : 5.2272, val_loss : 24.0748, acc : 0.083\n","Epoch 1, loss : 2.8108, val_loss : 13.3855, acc : 0.167\n","Epoch 2, loss : 1.8528, val_loss : 6.8164, acc : 0.542\n","Epoch 3, loss : 1.4473, val_loss : 4.6168, acc : 0.542\n","Epoch 4, loss : 1.1246, val_loss : 4.1487, acc : 0.583\n","Epoch 5, loss : 0.9354, val_loss : 2.5178, acc : 0.625\n","Epoch 6, loss : 0.7090, val_loss : 2.2628, acc : 0.625\n","Epoch 7, loss : 0.5796, val_loss : 2.4890, acc : 0.792\n","Epoch 8, loss : 0.5044, val_loss : 1.8024, acc : 0.667\n","Epoch 9, loss : 0.4098, val_loss : 2.0921, acc : 0.792\n","Epoch 10, loss : 0.3472, val_loss : 1.3589, acc : 0.750\n","Epoch 11, loss : 0.2925, val_loss : 1.1582, acc : 0.750\n","Epoch 12, loss : 0.2360, val_loss : 0.9153, acc : 0.792\n","Epoch 13, loss : 0.2032, val_loss : 0.6477, acc : 0.792\n","Epoch 14, loss : 0.1666, val_loss : 0.5738, acc : 0.792\n","Epoch 15, loss : 0.1379, val_loss : 0.4917, acc : 0.792\n","Epoch 16, loss : 0.1187, val_loss : 0.3495, acc : 0.833\n","Epoch 17, loss : 0.1022, val_loss : 0.2759, acc : 0.917\n","Epoch 18, loss : 0.0885, val_loss : 0.2439, acc : 0.917\n","Epoch 19, loss : 0.0776, val_loss : 0.2230, acc : 0.917\n","Epoch 20, loss : 0.0686, val_loss : 0.2074, acc : 0.917\n","Epoch 21, loss : 0.0608, val_loss : 0.1992, acc : 0.958\n","Epoch 22, loss : 0.0538, val_loss : 0.1963, acc : 0.958\n","Epoch 23, loss : 0.0477, val_loss : 0.1944, acc : 0.958\n","Epoch 24, loss : 0.0419, val_loss : 0.1956, acc : 0.958\n","Epoch 25, loss : 0.0364, val_loss : 0.1979, acc : 0.958\n","Epoch 26, loss : 0.0316, val_loss : 0.2016, acc : 0.958\n","Epoch 27, loss : 0.0271, val_loss : 0.2056, acc : 0.958\n","Epoch 28, loss : 0.0226, val_loss : 0.2061, acc : 0.958\n","Epoch 29, loss : 0.0189, val_loss : 0.2134, acc : 0.958\n","Epoch 30, loss : 0.0155, val_loss : 0.2305, acc : 0.958\n","Epoch 31, loss : 0.0130, val_loss : 0.2497, acc : 0.958\n","Epoch 32, loss : 0.0111, val_loss : 0.2703, acc : 0.958\n","Epoch 33, loss : 0.0097, val_loss : 0.2923, acc : 0.958\n","Epoch 34, loss : 0.0085, val_loss : 0.3149, acc : 0.958\n","Epoch 35, loss : 0.0076, val_loss : 0.3384, acc : 0.917\n","Epoch 36, loss : 0.0068, val_loss : 0.3641, acc : 0.917\n","Epoch 37, loss : 0.0062, val_loss : 0.3840, acc : 0.917\n","Epoch 38, loss : 0.0056, val_loss : 0.4042, acc : 0.917\n","Epoch 39, loss : 0.0052, val_loss : 0.4113, acc : 0.917\n","Epoch 40, loss : 0.0048, val_loss : 0.4288, acc : 0.917\n","Epoch 41, loss : 0.0047, val_loss : 0.4364, acc : 0.917\n","Epoch 42, loss : 0.0046, val_loss : 0.4432, acc : 0.917\n","Epoch 43, loss : 0.0044, val_loss : 0.4365, acc : 0.917\n","Epoch 44, loss : 0.0043, val_loss : 0.4424, acc : 0.917\n","Epoch 45, loss : 0.0042, val_loss : 0.4292, acc : 0.917\n","Epoch 46, loss : 0.0041, val_loss : 0.4423, acc : 0.917\n","Epoch 47, loss : 0.0040, val_loss : 0.4177, acc : 0.917\n","Epoch 48, loss : 0.0039, val_loss : 0.4543, acc : 0.917\n","Epoch 49, loss : 0.0038, val_loss : 0.4092, acc : 0.917\n","Epoch 50, loss : 0.0037, val_loss : 0.4762, acc : 0.917\n","Epoch 51, loss : 0.0037, val_loss : 0.3821, acc : 0.917\n","Epoch 52, loss : 0.0037, val_loss : 0.5122, acc : 0.917\n","Epoch 53, loss : 0.0038, val_loss : 0.3471, acc : 0.917\n","Epoch 54, loss : 0.0038, val_loss : 0.5632, acc : 0.917\n","Epoch 55, loss : 0.0041, val_loss : 0.2969, acc : 0.958\n","Epoch 56, loss : 0.0040, val_loss : 0.6098, acc : 0.917\n","Epoch 57, loss : 0.0046, val_loss : 0.2603, acc : 0.958\n","Epoch 58, loss : 0.0044, val_loss : 0.6592, acc : 0.917\n","Epoch 59, loss : 0.0049, val_loss : 0.2435, acc : 0.958\n","Epoch 60, loss : 0.0048, val_loss : 0.6835, acc : 0.917\n","Epoch 61, loss : 0.0050, val_loss : 0.2340, acc : 0.958\n","Epoch 62, loss : 0.0049, val_loss : 0.7033, acc : 0.917\n","Epoch 63, loss : 0.0051, val_loss : 0.2292, acc : 0.958\n","Epoch 64, loss : 0.0050, val_loss : 0.7164, acc : 0.917\n","Epoch 65, loss : 0.0050, val_loss : 0.2320, acc : 0.958\n","Epoch 66, loss : 0.0049, val_loss : 0.7164, acc : 0.917\n","Epoch 67, loss : 0.0048, val_loss : 0.2377, acc : 0.958\n","Epoch 68, loss : 0.0045, val_loss : 0.7092, acc : 0.917\n","Epoch 69, loss : 0.0047, val_loss : 0.2429, acc : 0.958\n","Epoch 70, loss : 0.0042, val_loss : 0.7020, acc : 0.917\n","Epoch 71, loss : 0.0044, val_loss : 0.2490, acc : 0.958\n","Epoch 72, loss : 0.0038, val_loss : 0.6933, acc : 0.917\n","Epoch 73, loss : 0.0043, val_loss : 0.2533, acc : 0.958\n","Epoch 74, loss : 0.0036, val_loss : 0.6877, acc : 0.917\n","Epoch 75, loss : 0.0041, val_loss : 0.2583, acc : 0.958\n","Epoch 76, loss : 0.0033, val_loss : 0.6821, acc : 0.917\n","Epoch 77, loss : 0.0040, val_loss : 0.2625, acc : 0.958\n","Epoch 78, loss : 0.0032, val_loss : 0.6777, acc : 0.917\n","Epoch 79, loss : 0.0039, val_loss : 0.2655, acc : 0.958\n","Epoch 80, loss : 0.0030, val_loss : 0.6747, acc : 0.917\n","Epoch 81, loss : 0.0038, val_loss : 0.2661, acc : 0.958\n","Epoch 82, loss : 0.0028, val_loss : 0.6719, acc : 0.917\n","Epoch 83, loss : 0.0038, val_loss : 0.2642, acc : 0.958\n","Epoch 84, loss : 0.0028, val_loss : 0.6742, acc : 0.917\n","Epoch 85, loss : 0.0037, val_loss : 0.2635, acc : 0.958\n","Epoch 86, loss : 0.0027, val_loss : 0.6760, acc : 0.917\n","Epoch 87, loss : 0.0037, val_loss : 0.2627, acc : 0.958\n","Epoch 88, loss : 0.0026, val_loss : 0.6777, acc : 0.917\n","Epoch 89, loss : 0.0037, val_loss : 0.2618, acc : 0.958\n","Epoch 90, loss : 0.0026, val_loss : 0.6794, acc : 0.917\n","Epoch 91, loss : 0.0037, val_loss : 0.2600, acc : 0.958\n","Epoch 92, loss : 0.0025, val_loss : 0.6784, acc : 0.917\n","Epoch 93, loss : 0.0037, val_loss : 0.2571, acc : 0.958\n","Epoch 94, loss : 0.0024, val_loss : 0.6819, acc : 0.917\n","Epoch 95, loss : 0.0037, val_loss : 0.2562, acc : 0.958\n","Epoch 96, loss : 0.0024, val_loss : 0.6843, acc : 0.917\n","Epoch 97, loss : 0.0036, val_loss : 0.2557, acc : 0.958\n","Epoch 98, loss : 0.0023, val_loss : 0.6861, acc : 0.917\n","Epoch 99, loss : 0.0036, val_loss : 0.2554, acc : 0.958\n","test_acc : 1.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LoO4Ytyl5ZTO"},"source":["### 【問題4】House Pricesのモデルを作成"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"doyEKzob5aEF","executionInfo":{"status":"ok","timestamp":1616261309219,"user_tz":-540,"elapsed":2930,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"9cea8934-50af-43b1-bd1d-92d5fd7f0ced"},"source":["# データセットの読み込み\n","#dataset_path =\"./house_prices_advanced_regression_techniques/train.csv\"\n","df_house = pd.read_csv('drive/My Drive/Sprint13/train.csv', dtype = None)\n","\n","# データフレームから条件抽出\n","y = df_house[['SalePrice']]\n","X = df_house[['GrLivArea','YearBuilt']]\n","y = np.array(np.log1p(y))\n","X = np.array(np.log1p(X))\n","\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = \\\n","train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = \\\n","train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","\n","def regression_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    # 重みとバイアスの宣言\n","    weights = {\n","        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n","        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n","    }\n","    \n","    biases = {\n","        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n","        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n","        'b3': tf.Variable(tf.random_normal([n_classes]))\n","    }\n","    \n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    # tf.addと+は等価である\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] \n","    \n","    return layer_output\n","\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","\n","# ネットワーク構造の読み込み                               \n","logits = regression_net(X)\n","\n","# 目的関数\n","loss_op = tf.reduce_mean(tf.square(logits - Y))\n","\n","# 最適化手法\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","# 指標値計算\n","mean_square_error = tf.reduce_mean(tf.square(logits - Y))\n","\n","# variableの初期化\n","init = tf.global_variables_initializer()\n","\n","# 計算グラフの実行\n","with tf.Session() as sess:\n","    sess.run(init)\n","    \n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        #total_loss = 0\n","        total_mse = 0\n","        \n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            \n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            \n","            mse = sess.run(mean_square_error,\n","                                 feed_dict={X: mini_batch_x, Y: mini_batch_y}\n","            )\n","            #total_loss += loss\n","            total_mse += mse\n","            \n","        #total_loss /= n_samples\n","        total_mse /= n_samples\n","        \n","        val_mse = sess.run(mean_square_error,\n","                                     feed_dict={X: X_val, Y: y_val}\n","        )\n","        print(\"Epoch {},  mse : {:.3f}, val_mse : {:.3f}\"\n","              .format(epoch, mse, val_mse))\n","    test_mse = sess.run(mean_square_error, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_mse : {:.3f}\".format(test_mse))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 0,  mse : 13.365, val_mse : 17.323\n","Epoch 1,  mse : 2.984, val_mse : 3.414\n","Epoch 2,  mse : 0.450, val_mse : 0.585\n","Epoch 3,  mse : 0.193, val_mse : 0.361\n","Epoch 4,  mse : 0.245, val_mse : 0.432\n","Epoch 5,  mse : 0.354, val_mse : 0.564\n","Epoch 6,  mse : 0.275, val_mse : 0.466\n","Epoch 7,  mse : 0.182, val_mse : 0.347\n","Epoch 8,  mse : 0.304, val_mse : 0.502\n","Epoch 9,  mse : 0.162, val_mse : 0.321\n","test_mse : 0.298\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tBOkLXiykdtO"},"source":["### 【問題5】MNISTのモデルを作成¶"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LzbLSNQXmqR4","executionInfo":{"status":"ok","timestamp":1616261431791,"user_tz":-540,"elapsed":57055,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"91ef4858-4864-48ad-f578-2e6a43f2424e"},"source":["#!pip install --upgrade tensorflow==2.4.1"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/dc/e8c5e7983866fa4ef3fd619faa35f660b95b01a2ab62b3884f038ccab542/tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n","\u001b[K     |████████████████████████████████| 394.3MB 27kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n","Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n","Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n","Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.12.4)\n","Collecting tensorflow-estimator<2.5.0,>=2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n","\u001b[K     |████████████████████████████████| 471kB 37.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n","Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.36.2)\n","Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n","Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n","Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n","Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.10.0)\n","Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.3.3)\n","Collecting tensorboard~=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 37.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.4.1) (54.1.2)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.3)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.27.1)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.1)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.7.2)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 1.14.0\n","    Uninstalling tensorflow-estimator-1.14.0:\n","      Successfully uninstalled tensorflow-estimator-1.14.0\n","  Found existing installation: tensorboard 1.14.0\n","    Uninstalling tensorboard-1.14.0:\n","      Successfully uninstalled tensorboard-1.14.0\n","  Found existing installation: tensorflow 1.14.0\n","    Uninstalling tensorflow-1.14.0:\n","      Successfully uninstalled tensorflow-1.14.0\n","Successfully installed tensorboard-2.4.1 tensorflow-2.4.1 tensorflow-estimator-2.4.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow","tensorflow_estimator"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7Qe8bZjUkdb2","executionInfo":{"status":"ok","timestamp":1616262972663,"user_tz":-540,"elapsed":779,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}}},"source":["# MNISTデータセットのダウンロード\n","#from keras.datasets import mnist\n","mnist = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joUsYOi7oepC","executionInfo":{"status":"ok","timestamp":1616262974081,"user_tz":-540,"elapsed":567,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"dc6f1240-4a18-492e-9efe-8234c7c83e89"},"source":["X_train = X_train.reshape(-1, 784)\n","X_test = X_test.reshape(-1, 784)\n","\n","y_test = y_test.astype(np.int64)[:, np.newaxis]\n","X_train = np.array(X_train)\n","X_test =np.array(X_test)\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)\n","y_train = y_train.reshape(-1, 1) == np.arange(10)\n","y_test=y_test.reshape(-1, 1) == np.arange(10)\n"],"execution_count":38,"outputs":[{"output_type":"stream","text":["(10000, 784)\n","(10000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ai__p5COk2p6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616262976327,"user_tz":-540,"elapsed":563,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"eb8e858d-f3d8-4e02-b917-3c89e2dd6a91"},"source":["def split_data(data, permutation, val_size_rate=0.2):\n","    data = data[permutation]\n","    val_size = int(len(data) * val_size_rate)\n","    val = data[:val_size]\n","    train = data[val_size:]\n","    return train, val\n","\n","permutation = np.random.permutation(np.arange(len(X_train)))\n","X_train, X_val = split_data(X_train, permutation)\n","y_train, y_val = split_data(y_train, permutation)\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["(48000, 784)\n","(48000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wH6gUcBClE0B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616263369707,"user_tz":-540,"elapsed":99191,"user":{"displayName":"Tomohisa Matsuda","photoUrl":"","userId":"04367270643618336704"}},"outputId":"fec2d924-2278-4138-a2e1-9620dd63288e"},"source":["class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.001\n","batch_size = 20\n","num_epochs = 15\n","n_hidden1 = 128\n","n_hidden2 = 64\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 10\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    tf.random.set_random_seed(0)\n","    # 重みとバイアスの宣言\n","    weights = {\n","        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n","        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n","    }\n","    biases = {\n","        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n","        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n","        'b3': tf.Variable(tf.random_normal([n_classes]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n","    return layer_output\n","# ネットワーク構造の読み込み                               \n","logits = example_net(X)\n","# 目的関数\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits))\n","# 最適化手法\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# 推定結果\n","correct_pred = tf.equal(tf.argmax(Y,1 ), tf.argmax(logits,1))\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","# variableの初期化\n","init = tf.global_variables_initializer()\n","\n","# 計算グラフの実行\n","with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n","        total_loss = 0\n","        total_acc = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","        total_loss /= n_samples\n","        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 494.3287, val_loss : 3419.4294, acc : 0.857\n","Epoch 1, loss : 111.0291, val_loss : 1956.3787, acc : 0.889\n","Epoch 2, loss : 60.6219, val_loss : 1403.7091, acc : 0.907\n","Epoch 3, loss : 37.2614, val_loss : 1109.4105, acc : 0.914\n","Epoch 4, loss : 24.5054, val_loss : 954.5103, acc : 0.920\n","Epoch 5, loss : 16.8326, val_loss : 881.5616, acc : 0.921\n","Epoch 6, loss : 11.8580, val_loss : 774.0517, acc : 0.925\n","Epoch 7, loss : 8.6924, val_loss : 707.9290, acc : 0.927\n","Epoch 8, loss : 6.5745, val_loss : 665.4524, acc : 0.928\n","Epoch 9, loss : 4.8952, val_loss : 636.8006, acc : 0.931\n","Epoch 10, loss : 3.8880, val_loss : 606.1075, acc : 0.934\n","Epoch 11, loss : 3.0345, val_loss : 598.6090, acc : 0.935\n","Epoch 12, loss : 2.4870, val_loss : 559.7744, acc : 0.935\n","Epoch 13, loss : 1.9846, val_loss : 541.8394, acc : 0.937\n","Epoch 14, loss : 1.6857, val_loss : 535.0844, acc : 0.939\n","test_acc : 0.942\n"],"name":"stdout"}]}]}