{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc  #ガベージコレクション\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm #タカドゥム　プログレスバーの表示\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/sample_submission.csv')\n",
    "depth = pd.read_csv('./input/depths.csv')\n",
    "\n",
    "train_src = './input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')  #trainにdepthを結合 pandasの便利なメソッド\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8c4db69c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337, shuffle=True)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)  #Center(encorder5の出力をCNN+BN+ReLU)とencorder5の出力を結合している。\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 31189s 10s/step - loss: 0.7998 - my_iou_metric: 0.2017 - val_loss: 0.9494 - val_my_iou_metric: 0.2879\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.28788, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 1  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:00<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4129 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.318054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.047944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.248875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.280250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.313250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.352938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.412875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.318054\n",
       "std     0.204939   0.047944\n",
       "min     0.200000   0.248875\n",
       "25%     0.370000   0.280250\n",
       "50%     0.540000   0.313250\n",
       "75%     0.710000   0.352938\n",
       "max     0.880000   0.412875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='threshold'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】コードレビュー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・前回使用した実装とはどのように違うのか\n",
    "\n",
    "　　→レイヤー１層ごとに記載するのではなく、同じ処理の繰り返しとなる部分について\n",
    "  \n",
    "  　　　ブロック化させている。（コードが短くなる）\n",
    "  \n",
    "・転移学習をどのように行っているか\n",
    "\n",
    "　　→ResNet50をimportしてimagenetの学習済データを使用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】コードの書き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "def unet_vgg(input_size,\n",
    "                decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part    \n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    #model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,677,489\n",
      "Trainable params: 28,672,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 16242s 5s/step - loss: 0.4044 - acc: 0.8281 - val_loss: 0.5504 - val_acc: 0.7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_my_iou_metric available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_my_iou_metric` which is not available. Available metrics are: val_loss,val_acc,loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 1  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】学習・推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet, VGGの学習・推定結果は上記セル参照のこと。\n",
    "\n",
    "今回はエポック数を小さくして計算しているため正確さには欠けるが、両手法でLoss、精度ともに大きな差は見られなかった。ただエポックを増やせばResNetの方が層が深いためLoss等がより良い値になるはずであると考える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
